from bioscience.base import *

import math
import sys
import os
import threading
import warnings
import numpy as np
import time


###########
# Kendall #
###########
def kendall(dataset, threshold = 0.7, deviceCount = 0, mode = 1, debug = False):
    """
    Application of the Kendall correlation method.
    
    :param dataset: The dataset object to be binarized.
    :type dataset: :class:`bioscience.base.models.Dataset`
    
    :param threshold: The value for the threshold must be between 0 and 1. The default threshold is 0.7.
    :type threshold: float, optional
    
    param deviceCount: Number of GPU devices to execute
    :type deviceCount: int
    
    :param mode: Type of execution of the algorithm: `mode=1` for sequential execution, `mode=2` for parallel execution on CPUs and `mode=3` for execution on a multi-GPU architecture.
    :type mode: int
    
    :return: A CorrelationModel object that stores values generated by a correlation method.
    :rtype: :class:`bioscience.base.models.CorrelationModel`      
    """ 
    
    if threshold < 0:
        threshold = 0
    elif threshold > 1:
        threshold = 1
    
    oModel = None
    if (dataset is not None) and (0.0 <= threshold <= 1.0):
        sMode = ""
        if mode == 2: # NUMBA: CPU Parallel mode
            # To be developed
            sMode = "NUMBA - CPU Parallel mode (to be developed)"
        elif mode == 3: # NUMBA: GPU Parallel mode
            # To be developed
            sMode = "NUMBA - GPU Parallel mode (to be developed)"
        else: # Sequential mode
            oModel = __kendallSequential(dataset, threshold, debug)
            deviceCount = 0
            sMode = "CPU Sequential"
    
    return oModel

def __kendallSequential(dataset, threshold, debug):
    iRows = dataset.data.shape[0]
    iCols = dataset.data.shape[1]
    fExecutionTime = None
    
    lCombination = maxPairs = 0
    for i in range(1, iCols):
        lCombination += i
        
    for i in range(iRows):
        for j in range(i + 1, iRows):
            maxPairs += 1
    
    resultsCorrelation = np.zeros(maxPairs)    
    
    if debug == True:
        start_time = time.time()
        
    for pattern, value in enumerate(resultsCorrelation):
        
        # Get R1 and R2 from index results vector
        r1 = 0
        r2 = -1
        auxPat = pattern - iRows + 1
        
        if auxPat < 0:
            r2 = auxPat + iRows

        j = iRows - 2
        while r2 == -1:
            auxPat -= j
            r1 += 1
            if auxPat < 0:
                r2 = (j + auxPat) + (r1 + 1)
            j -= 1
        
        if r1 < iRows and r2 < iRows:
            
            # Calculation maxValue index of iCol1
            iConcordant = iDiscordant = tiersGene1 = tiersGene2 = 0
            dKendall = -1
            
            iPosMaxValue = 0
            fMaxValue = dataset.data[r1][0]
            for iCol1 in range(1, iCols):
                if fMaxValue < dataset.data[r1][iCol1]:
                    fMaxValue = dataset.data[r1][iCol1]
                    iPosMaxValue = iCol1
            
            # Calculation concordant and discordant pairs
            for iCol1 in range(iCols):
                if iCol1 != iPosMaxValue:
                    for iCol2 in range(iCols):
                        if iCol1 != iCol2 and dataset.data[r1][iCol1] < dataset.data[r1][iCol2]:
                            if dataset.data[r2][iCol2] > dataset.data[r2][iCol1]:
                                iConcordant += 1
                            if dataset.data[r2][iCol2] < dataset.data[r2][iCol1]:
                                iDiscordant += 1
            
            # Calculation tiers
            for iCol1 in range(iCols):
                for iCol2 in range(iCol1 + 1, iCols):
                    # Gene 1
                    if dataset.data[r1][iCol1] == dataset.data[r1][iCol2]:
                        tiersGene1 += 1

                    # Gene 2
                    if dataset.data[r2][iCol1] == dataset.data[r2][iCol2]:
                        tiersGene2 += 1
            
            # Calculate Kendall value
            if (lCombination - tiersGene1) * (lCombination - tiersGene2) != 0:
                dKendall = (iConcordant - iDiscordant) / math.sqrt((lCombination - tiersGene1) * (lCombination - tiersGene2))
                if dKendall < 0:
                    dKendall = dKendall * -1
                
                if dKendall < threshold:
                    dKendall = None
            else:
                dKendall = None
                        
        
        resultsCorrelation[pattern] = dKendall
    
    if debug == True:
        end_time = time.time()
        fExecutionTime = end_time - start_time
    
    oCorrelationResults = CorrelationModel(results=resultsCorrelation, rows = iRows, executionTime=fExecutionTime)
    return oCorrelationResults
    
############
# Spearman #
############
def spearman(dataset, threshold = 0.7, deviceCount = 0, mode = 1, debug = False):
    """
    Application of the Spearman correlation method.
    
    :param dataset: The dataset object to be binarized.
    :type dataset: :class:`bioscience.base.models.Dataset`
    
    :param threshold: The value for the threshold must be between 0 and 1. The default threshold is 0.7.
    :type threshold: float, optional
    
    param deviceCount: Number of GPU devices to execute
    :type deviceCount: int
    
    :param mode: Type of execution of the algorithm: `mode=1` for sequential execution, `mode=2` for parallel execution on CPUs and `mode=3` for execution on a multi-GPU architecture.
    :type mode: int
    
    :return: A CorrelationModel object that stores values generated by a correlation method.
    :rtype: :class:`bioscience.base.models.CorrelationModel`      
    """ 
    
    if threshold < 0:
        threshold = 0
    elif threshold > 1:
        threshold = 1
    
    oModel = None
    if (dataset is not None) and (0.0 <= threshold <= 1.0):
        sMode = ""
        if mode == 2: # NUMBA: CPU Parallel mode
            # To be developed
            sMode = "NUMBA - CPU Parallel mode (to be developed)"
        elif mode == 3: # NUMBA: GPU Parallel mode
            # To be developed
            sMode = "NUMBA - GPU Parallel mode (to be developed)"
        else: # Sequential mode
            oModel = __spearmanSequential(dataset, threshold, debug)
            deviceCount = 0
            sMode = "CPU Sequential"
    
    return oModel

def __spearmanSequential(dataset, threshold, debug):
    iRows = dataset.data.shape[0]
    iCols = dataset.data.shape[1]
    fExecutionTime = None    
    
    maxPairs = 0
    for i in range(iRows):
        for j in range(i + 1, iRows):
            maxPairs += 1
    
    fSpearmanRankG1 = np.zeros((maxPairs,iCols))
    fSpearmanRankG2 = np.zeros((maxPairs,iCols))
    fSpearmanStats = np.zeros((maxPairs,4)) # [0] --> Mean of rank G1; [1] --> Mean of rank G2; ; [2] --> aux ; [3] --> aux
    resultsCorrelation = np.zeros(maxPairs)    
    
    if debug == True:
        start_time = time.time()
    
    pattern = 0
    while pattern < maxPairs:
        
        # Get R1 and R2 from index results vector
        r1 = 0
        r2 = -1
        auxPat = pattern - iRows + 1
        
        if auxPat < 0:
            r2 = auxPat + iRows

        j = iRows - 2
        while r2 == -1:
            auxPat -= j
            r1 += 1
            if auxPat < 0:
                r2 = (j + auxPat) + (r1 + 1)
            j -= 1
        
        if r1 < iRows and r2 < iRows:
            
            # Calculation G1 and G2 ranks
            for iConditions in range(iCols):
                numEqualOrdG1 = readG1 = numEqualOrdG2 = readG2 = 1.0
                for iCont in range(iCols):
                    if iCont != iConditions:
                        if dataset.data[r1][iCont] < dataset.data[r1][iConditions]:
                            readG1 += 1.0
                        elif dataset.data[r1][iCont] == dataset.data[r1][iConditions]:
                            numEqualOrdG1 += 1.0

                        if dataset.data[r2][iCont] < dataset.data[r2][iConditions]:
                            readG2 += 1.0
                        elif dataset.data[r2][iCont] == dataset.data[r2][iConditions]:
                            numEqualOrdG2 += 1.0

                fSpearmanRankG1[pattern][iConditions] = readG1 + ((numEqualOrdG1 - 1.0) * 0.5)
                fSpearmanRankG2[pattern][iConditions] = readG2 + ((numEqualOrdG2 - 1.0) * 0.5)
                fSpearmanStats[pattern][0] += fSpearmanRankG1[pattern][iConditions]
                fSpearmanStats[pattern][1] += fSpearmanRankG2[pattern][iConditions]

            fSpearmanStats[pattern][0] /= iCols
            fSpearmanStats[pattern][1] /= iCols
            
            
            # Covariance Spearman calculation
            for iConditions in range(iCols):
                fSpearmanStats[pattern][2] += (fSpearmanRankG1[pattern][iConditions] - fSpearmanStats[pattern][0]) * (fSpearmanRankG2[pattern][iConditions] - fSpearmanStats[pattern][1])
            resultsCorrelation[pattern] = fSpearmanStats[pattern][2] / (iCols - 1)
            
            # Spearman calculation values
            fSpearmanStats[pattern][2] = 0
            fSpearmanStats[pattern][3] = 0
            for iConditions in range(iCols):
                fSpearmanStats[pattern][2] += (fSpearmanRankG1[pattern][iConditions] - fSpearmanStats[pattern][0]) * (fSpearmanRankG1[pattern][iConditions] - fSpearmanStats[pattern][0])
                fSpearmanStats[pattern][3] += (fSpearmanRankG2[pattern][iConditions] - fSpearmanStats[pattern][1]) * (fSpearmanRankG2[pattern][iConditions] - fSpearmanStats[pattern][1])
            fSpearmanStats[pattern][2] = math.sqrt(fSpearmanStats[pattern][2] / (iCols - 1))
            fSpearmanStats[pattern][3] = math.sqrt(fSpearmanStats[pattern][3] / (iCols - 1))
            
            dSpearman = None
            if (fSpearmanStats[pattern][2] * fSpearmanStats[pattern][3]) != 0:
                dSpearman = resultsCorrelation[pattern] / (fSpearmanStats[pattern][2] * fSpearmanStats[pattern][3])
                   
            if dSpearman != None:
                if dSpearman < 0:
                    dSpearman = dSpearman * -1
                    
                if dSpearman < threshold:
                    dSpearman = None
            
            resultsCorrelation[pattern] = dSpearman
        
        pattern += 1
    
    if debug == True:
        end_time = time.time()
        fExecutionTime = end_time - start_time
    
    oCorrelationResults = CorrelationModel(results=resultsCorrelation, rows = iRows, executionTime=fExecutionTime)
    return oCorrelationResults

#######
# NMI #
#######
def nmi(dataset, threshold = 0.7, deviceCount = 0, mode = 1, debug = False):
    """
    Application of the Normalized Mutual Information (NMI) correlation method.
    
    :param dataset: The dataset object to be binarized.
    :type dataset: :class:`bioscience.base.models.Dataset`
    
    :param threshold: The value for the threshold must be between 0 and 1. The default threshold is 0.7.
    :type threshold: float, optional
    
    param deviceCount: Number of GPU devices to execute
    :type deviceCount: int
    
    :param mode: Type of execution of the algorithm: `mode=1` for sequential execution, `mode=2` for parallel execution on CPUs and `mode=3` for execution on a multi-GPU architecture.
    :type mode: int
    
    :return: A CorrelationModel object that stores values generated by a correlation method.
    :rtype: :class:`bioscience.base.models.CorrelationModel`      
    """ 
    
    if threshold < 0:
        threshold = 0
    elif threshold > 1:
        threshold = 1
    
    oModel = None
    if (dataset is not None) and (0.0 <= threshold <= 1.0):
        sMode = ""
        if mode == 2: # NUMBA: CPU Parallel mode
            # To be developed
            sMode = "NUMBA - CPU Parallel mode (to be developed)"
        elif mode == 3: # NUMBA: GPU Parallel mode
            # To be developed
            sMode = "NUMBA - GPU Parallel mode (to be developed)"
        else: # Sequential mode
            oModel = __nmiSequential(dataset, threshold, debug)
            deviceCount = 0
            sMode = "CPU Sequential"
    
    return oModel

def __normalizedNmi(dataset):    
    iRows = dataset.data.shape[0]
    iCols = dataset.data.shape[1]
    maxValueDataset = -1
    dataNormalized = np.zeros((iRows,iCols+1), dtype=np.int64)
    for ulCountRow in range(iRows):
        maxValue = np.int64(np.floor(dataset.data[ulCountRow][0]))
        minValue = np.int64(np.floor(dataset.data[ulCountRow][0]))
        for ulCountCol in range(iCols):
            iExp = np.int64(np.floor(dataset.data[ulCountRow][ulCountCol]))
            dataNormalized[ulCountRow][ulCountCol] = iExp     
            if iExp < minValue:
                minValue = iExp
            if iExp > maxValue:
                maxValue = iExp
        
        for ulCountCol in range(iCols):
            dataNormalized[ulCountRow][ulCountCol] = dataset.data[ulCountRow][ulCountCol] - minValue
        
        maxValue = maxValue - minValue + 1
        dataNormalized[ulCountRow][iCols] = maxValue
        if maxValueDataset < maxValue:
            maxValueDataset = maxValue
    
    return dataNormalized, maxValueDataset
        

def __nmiSequential(dataset, threshold, debug):
    iRows = dataset.data.shape[0]
    iCols = dataset.data.shape[1]
    fExecutionTime = None
    
    maxPairs = 0
    for i in range(iRows):
        for j in range(i + 1, iRows):
            maxPairs += 1
            
    # Get maxValueDataset and dataNormalized
    dataNormalized, maxValueDataset = __normalizedNmi(dataset)
    nmiResults = np.full((maxPairs,((maxValueDataset + maxValueDataset) + (maxValueDataset * maxValueDataset) + 3)),-1, dtype=np.float64) # [0] --> Mutual information ::: NMI [1] --> entropyGen1 ::: [2] --> entropyGen2 ::: [3 - maxValueDataset] --> probMaps
    
    if debug == True:
        start_time = time.time()
    
    pattern = 0
    while pattern < maxPairs:
        
        # Get R1 and R2 from index results vector
        r1 = 0
        r2 = -1
        auxPat = pattern - iRows + 1
        
        if auxPat < 0:
            r2 = auxPat + iRows

        j = iRows - 2
        while r2 == -1:
            auxPat -= j
            r1 += 1
            if auxPat < 0:
                r2 = (j + auxPat) + (r1 + 1)
            j -= 1
        
        if r1 < iRows and r2 < iRows:
            
            # NMI: Calculation mutual information
            for iColumn in range(iCols):
                valGen1Column = dataNormalized[r1][iColumn]
                valGen2Column = dataNormalized[r2][iColumn]                
                nmiResults[pattern][valGen1Column + 3] += 1
                nmiResults[pattern][maxValueDataset + 3 + valGen2Column] += 1
                nmiResults[pattern][(valGen1Column + maxValueDataset * valGen2Column) + (maxValueDataset + maxValueDataset) + 3] += 1           

            for i in range(3, ((maxValueDataset + maxValueDataset) + (maxValueDataset * maxValueDataset) + 3)):
                if nmiResults[pattern][i] != -1:
                    nmiResults[pattern][i] = (nmiResults[pattern][i] + 1) / iCols   
                    
            mi = 0.0
            for iCont in range(maxValueDataset * maxValueDataset):
                index = (maxValueDataset + maxValueDataset) + 3 + iCont
                if nmiResults[pattern][index] > 0:
                    doubleValue = nmiResults[pattern][index]
                    doubleValue2 = nmiResults[pattern][(iCont % maxValueDataset) + 3]
                    doubleValue3 = nmiResults[pattern][(iCont // maxValueDataset) + 3 + maxValueDataset]
                    if doubleValue > 0 and doubleValue2 > 0 and doubleValue3 > 0:
                        mi += doubleValue * math.log(doubleValue / (doubleValue2 * doubleValue3))

            mi /= math.log(2)
            nmiResults[pattern][0] = mi
            
            # NMI: Calculation entropy
            maxValGene1 = dataNormalized[r1][iCols]
            maxValGene2 = dataNormalized[r2][iCols]
            
            for i in range(3, ((maxValueDataset + maxValueDataset) + (maxValueDataset * maxValueDataset) + 3)):
                nmiResults[pattern][i] = -1
            
            for iColumn in range(iCols):
                valGen1Column = int(np.floor(dataNormalized[r1][iColumn]))
                valGen2Column = int(np.floor(dataNormalized[r2][iColumn]))
                nmiResults[pattern][valGen1Column + 3] += 1
                nmiResults[pattern][maxValueDataset + 3 + valGen2Column] += 1
            
            for i in range(3, ((maxValueDataset + maxValueDataset) + (maxValueDataset * maxValueDataset) + 3)):
                if nmiResults[pattern][i] != -1:
                    nmiResults[pattern][i] = (nmiResults[pattern][i] + 1) / iCols
            
            dEntropyG1 = 0.0
            for i in range(maxValGene1):
                varAuxG1 = nmiResults[pattern][3 + i]
                if varAuxG1 > 0:
                    dEntropyG1 -= varAuxG1 * math.log(varAuxG1)

            dEntropyG2 = 0.0
            for i in range(maxValGene2):
                varAuxG2 = nmiResults[pattern][3 + i + maxValueDataset]
                if varAuxG2 > 0:
                    dEntropyG2 -= varAuxG2 * math.log(varAuxG2)
            
            dEntropyG1 /= math.log(2)
            dEntropyG2 /= math.log(2)

            nmiResults[pattern][1] = dEntropyG1
            nmiResults[pattern][2] = dEntropyG2
            
            # Get calculation value
            denom = (nmiResults[pattern][1] + nmiResults[pattern][2])
            if denom > 0:
                dNMI = 2.0 * nmiResults[pattern][0] / denom
            else:
                dNMI = 0  # Si denom es 0, se asigna dNMI a 0
                
            if dNMI < 0:
                dNMI = dNMI * -1
                    
            if dNMI < threshold:
                dNMI = None
            
            nmiResults[pattern][0] = dNMI
                
        pattern += 1
    
    if debug == True:
        end_time = time.time()
        fExecutionTime = end_time - start_time
    
    oCorrelationResults = CorrelationModel(results=nmiResults[:,0], rows = iRows, executionTime=fExecutionTime)
    return oCorrelationResults